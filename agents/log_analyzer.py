import json
from datetime import datetime
from collections import defaultdict

# ==============================
# Configuration
# ==============================
TIME_WINDOW_MINUTES = 5
RISK_THRESHOLD = 40

# ==============================
# Utility Functions
# ==============================
def parse_time(ts):
    try:
        return datetime.fromisoformat(ts.replace("Z", ""))
    except Exception:
        return None

def load_scaled_logs(file_path):
    """
    Load scaled-down logs generated by ScaleDown agent
    """
    logs = []
    with open(file_path, "r") as f:
        for line in f:
            logs.append(json.loads(line))
    return logs

# ==============================
# Feature Extraction
# ==============================
def extract_features(logs):
    """
    Convert logs into behavioral features
    """
    features = []

    for log in logs:
        feature = {
            "source_ip": log["source_ip"],
            "event_type": log["event_type"],
            "event_count": log["event_count"],
            "max_severity": log["max_severity"],

            # Behavioral flags
            "is_bruteforce": log["event_type"] == "AUTH_FAIL" and log["event_count"] > 5,
            "is_port_scan": log["event_type"] == "PORT_SCAN" and log["event_count"] > 10,
            "is_malware": log["event_type"] == "MALWARE_ALERT"
        }

        features.append(feature)

    return features

# ==============================
# Risk Scoring
# ==============================
def calculate_risk_score(feature):
    """
    Calculate security risk score for an event
    """
    score = 0

    if feature["is_bruteforce"]:
        score += 30

    if feature["is_port_scan"]:
        score += 25

    if feature["is_malware"]:
        score += 40

    score += feature["max_severity"] * 2
    score += min(feature["event_count"], 20)

    return score

# ==============================
# Main Analyzer Pipeline
# ==============================
def analyze_logs(input_file, output_file):
    """
    Full log analysis pipeline
    """
    logs = load_scaled_logs(input_file)
    features = extract_features(logs)

    analyzed_events = []

    for feature in features:
        feature["risk_score"] = calculate_risk_score(feature)
        feature["label"] = (
            "SUSPICIOUS" if feature["risk_score"] >= RISK_THRESHOLD else "NORMAL"
        )

        analyzed_events.append(feature)

    with open(output_file, "w") as f:
        for event in analyzed_events:
            f.write(json.dumps(event) + "\n")

    print(f"[Log Analyzer] Processed {len(analyzed_events)} events")
